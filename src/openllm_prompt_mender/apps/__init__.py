

{'content': 'Your input fields are:\n'
            "1. `requirements` (str): The user's requirements or instructions "
            'for the template.\n'
            '2. `template` (str): The generated template that needs to be '
            'evaluated.\n'
            'Your output fields are:\n'
            '1. `reasoning` (str): \n'
            '2. `general_score` (float): Overall quality score of the '
            'template, from 0.0 to 1.0.\n'
            '3. `tone_score` (float): Score (0.0–1.0) evaluating how well the '
            "template's tone matches the intended style or voice.\n"
            '4. `scenario_alignment_score` (float): Score (0.0–1.0) measuring '
            'how well the template fits the specified scenario.\n'
            '5. `audience_match_score` (float): Score (0.0–1.0) assessing '
            'whether the template is appropriate for the target audience.\n'
            '6. `language_consistency_score` (float): A score between 0.0 and '
            '1.0 indicating how consistent the language of the template is '
            'with the language used in the requirements. Score 1.0 means fully '
            'consistent, and 0.0 means completely inconsistent. If the '
            'requirements explicitly request a specific language, evaluate '
            'consistency against that requested language instead.\n'
            '7. `rationale` (str): A concise explanation justifying the scores '
            'assigned for each evaluation dimension.\n'
            'All interactions will be structured in the following way, with '
            'the appropriate values filled in.\n'
            '\n'
            '[[ ## requirements ## ]]\n'
            '{requirements}\n'
            '\n'
            '[[ ## template ## ]]\n'
            '{template}\n'
            '\n'
            '[[ ## reasoning ## ]]\n'
            '{reasoning}\n'
            '\n'
            '[[ ## general_score ## ]]\n'
            '{general_score}        # note: the value you produce must be a '
            'single float value\n'
            '\n'
            '[[ ## tone_score ## ]]\n'
            '{tone_score}        # note: the value you produce must be a '
            'single float value\n'
            '\n'
            '[[ ## scenario_alignment_score ## ]]\n'
            '{scenario_alignment_score}        # note: the value you produce '
            'must be a single float value\n'
            '\n'
            '[[ ## audience_match_score ## ]]\n'
            '{audience_match_score}        # note: the value you produce must '
            'be a single float value\n'
            '\n'
            '[[ ## language_consistency_score ## ]]\n'
            '{language_consistency_score}        # note: the value you produce '
            'must be a single float value\n'
            '\n'
            '[[ ## rationale ## ]]\n'
            '{rationale}\n'
            '\n'
            '[[ ## completed ## ]]\n'
            'In adhering to this structure, your objective is: \n'
            '        Evaluate the quality of a generated template based on '
            'user requirements.\n'
            '        \n'
            '        Assessment criteria:\n'
            '        1. Clarity and conciseness of the template.\n'
            '        2. Ease of understanding and usability.\n'
            '        3. Flexibility for modification and extension.\n'
            "        4. Alignment with the user's requirements, intended "
            'scenario, audience, and style.\n'
            '        5. Match the output language to the requirements unless a '
            'specific language is requested.',
 'role': 'system'}
{'content': '[[ ## requirements ## ]]\n'
            '技術者向け\n'
            '\n'
            '[[ ## template ## ]]\n'
            '# 技術者向け会議 – 要約テンプレート\n'
            '\n'
            '## 会議の目的\n'
            '- 技術的な課題の共有と解決策の検討\n'
            '- 開発プロセスやアーキテクチャに関する情報を共有\n'
            '- チーム間の連携強化と課題の明確化\n'
            '\n'
            '## 参加者\n'
            '- 名前 — 業務分野／役割 — 関連するシステム／プロジェクト\n'
            '- （追加参加者）\n'
            '\n'
            '## 会議のスケジュール\n'
            '1. 事前準備・背景情報共有  \n'
            '2. 現在の課題のレビュー（現状・影響範囲）  \n'
            '3. 原因分析と仮説検証  \n'
            '4. 解決策の提案と評価（技術的・実行可能性）  \n'
            '5. 責任の明確化とスケジューリング  \n'
            '6. 次回会議の予定とアクションアイテムの確定\n'
            '\n'
            '## 重要なキーワード・用語\n'
            '- パフォーマンス・ゲート（Performance Gate）  \n'
            '- リスク・インデックス（Risk Index）  \n'
            '- バージョン管理（Version Control）  \n'
            '- CI/CD フロー  \n'
            '- デプロイ・マトリクス  \n'
            '- エラーログ（Error Log）  \n'
            '- プロダクション・インシデント\n'
            '\n'
            '## 論点・課題（1つずつ明確に）\n'
            '- 課題ID：  \n'
            '- タイトル：  \n'
            '- 現状の状況／症状：  \n'
            '- 影響範囲（システム／モジュール／ユーザー）：  \n'
            '- 仮説／根因（Root Cause Hypothesis）：  \n'
            '- 検証方法／ログ／データ：  \n'
            '- 提案解決策（技術的アプローチ）：  \n'
            '- 実装の難易度／リスク（高／中／低）：  \n'
            '- 担当者／責任者：  \n'
            '- スケジュール（見積もり／見積もり期間）：  \n'
            '- 必要なリソース（インフラ／ツール／人材）：  \n'
            '- 他の関連課題との関連性（リンク／依存）：  \n'
            '- 次のアクション（具体的なステップ）：\n'
            '\n'
            '（※ 課題ごとに上記項目を記載。課題IDは連番で管理）\n'
            '\n'
            '## アクションアイテム\n'
            '- アクション：  \n'
            '  - 内容：  \n'
            '  - 責任者：  \n'
            '  - 期限：  \n'
            '  - ステータス（進行中／完了／延期）：  \n'
            '  - 関連課題ID：\n'
            '\n'
            '## 内部評価基準（技術的基準）\n'
            '- パフォーマンス：レスポンス時間、スループット、エラーレート  \n'
            '- リスク：セキュリティ、可用性、依存性  \n'
            '- 可読性／保守性：コードの可読性、ドキュメンテーション  \n'
            '- テストカバレッジ：ユニットテスト、統合テスト、E2Eテスト  \n'
            '- スケーラビリティ：今後の拡張可能性\n'
            '\n'
            '## 今後のステップ\n'
            '- 次回会議の日時／議事録共有タイミング  \n'
            '- チーム間の情報共有ルート（Slack、Jira、Confluence）  \n'
            '- システムの監視／ログ収集の強化スケジュール  \n'
            '- デプロイの自動化プロセスの進捗確認\n'
            '\n'
            '## 補足資料／リンク\n'
            '- Jira タスクリンク  \n'
            '- Git リポジトリ（ブランチ／コミットハッシュ）  \n'
            '- ログファイル／監視データ（S3／CloudWatch／Prometheus）  \n'
            '- 既存ドキュメント／アーキテクチャ図\n'
            '\n'
            'Respond with the corresponding output fields, starting with the '
            'field `[[ ## reasoning ## ]]`, then `[[ ## general_score ## ]]` '
            '(must be formatted as a valid Python float), then `[[ ## '
            'tone_score ## ]]` (must be formatted as a valid Python float), '
            'then `[[ ## scenario_alignment_score ## ]]` (must be formatted as '
            'a valid Python float), then `[[ ## audience_match_score ## ]]` '
            '(must be formatted as a valid Python float), then `[[ ## '
            'language_consistency_score ## ]]` (must be formatted as a valid '
            'Python float), then `[[ ## rationale ## ]]`, and then ending with '
            'the marker for `[[ ## completed ## ]]`.',
 'role': 'user'}